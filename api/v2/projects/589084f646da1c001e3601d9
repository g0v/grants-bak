{"_id":"589084f646da1c001e3601d9","title":"可以不要再給我文字雲了嗎","description":"# § 請以 80 ~ 120 字簡短地說明這個專案\n每日產生的開放政府資料含有大量的文本訊息，隨著影音資料的逐字稿自動化技術快速進展，文本分析 (text analytics) 是要了解觀點，呈現事實與多元價值者必備的瑞士刀。目前開源的軟體工具並沒有跟上自然語言處理的新發展，\n這個專案想要來當這個沒有人。\n\n# § 你過去參與過什麼開源開發計畫（open source project）？\n* 開放中文語料庫計劃 (Corpora Open and Search, COPENS)\n* 開放中文詞彙語意網路 (Chinese Wordnet, CWN)\n\n# § 這個計畫要解決什麼問題？\n解決 text mining 技術的老舊。每個人都使用一樣的套件 (tm, jieba) 與功能，讓文本分析都長一樣。除了斷詞，關鍵詞擷取，關聯詞/語意距離，詞頻為主的文字雲 之外，我們要提供比較深層的「語詞的行為素描」，包括：\n* (多語單位）lexical bundles(congram)/MWE\n*  (共現環境) concordance, collocation, colligation, lexical network（LSA, embeddings, social network of the lexicon）\n* (時間文類分佈）time-series analysis 語詞的時序分析，新詞存活力指標 stabilization measure。\n\n本專案成果亦可應用至不同國家或地區的中文。我們的團隊對於處理「世界華語」(World Chineses) 有基本的前處理經驗。例如，前處理中最重要的一個步驟是「斷詞」，我們曾經比較過不同斷詞器的結果（包括北京清華大學的分詞器THULAC、香港的切詞器LIVAC，和臺大語言所的深度斷詞DeepSeg）。在實作上，我們將針對不同語料地區來源提供選擇界面，經過不同前處理之後，後續的處理工具即可一體適用。\n\n# § 你為什麼要做這個計劃 （ 個人動機 ）？\n文本語意技術應該要來，也有潛力協助國會監督與公民社會發展。\n\n# § 你預計用什麼方式解決此問題？\n我們想要提供一個開放平台，使用者不需程式背景也可以自由上傳與分享文本語料，分析深度文本語意；\n也可以提供開放函式(cf. OpenCPU, https://www.opencpu.org/)\n\n# § 這個計畫的目標對象是誰？\n任何需要好玩一點的文本分析工具的公民黑客\n\n# § 這個計畫預計跟什麼團體合作？\n台灣大學語言學研究所 LOPE lab, 零時政府與文本挖掘有興趣的團體\n\n# § 過去有作過相關主題的計畫嗎？\n* COPENS [http://lopen.linguistics.ntu.edu.tw/copens/] (http://lopen.linguistics.ntu.edu.tw/copens/)\n* PTT corpus [http://lopen.linguistics.ntu.edu.tw/pttcorp/] (http://lopen.linguistics.ntu.edu.tw/pttcorp/)\n* Chinese WordSketch Engine [http://wordsketch.ling.sinica.edu.tw/] (http://wordsketch.ling.sinica.edu.tw/)\n\n# § 預計六個月內將花多少小時作這件事？需要多少經費？（30 萬到 50 萬）\n* 960 小時（預估每週 10 小時/人 ）\n* 47 萬元（預估開發經費）：\n   - 爬資料、設計、前後端、演算法 (40 萬)\n   - 雲端伺服器租借維護：(5 萬)\n   - 推廣行銷、使用者回饋：(2 萬)\n\n# § 打算如何讓社群參與以及回饋意見？\n* FB 粉絲帳號\n* 將進度的成果在社群的社團(R MLDM Monday, Taipei.py)分享，徵求意見。\n\n# § 請說明專案結束時，會產出的開源軟體套件或開放授權文件（請條列個別元件的輸入輸出或其功能）？\n程式碼採用 [MIT](https://hackmd.io/AwQwrAxsBM0KYFoDscCMAzBAWAHCRARqgJzEJjpwQDMAJkmFsXNUA=== \"MIT\")  授權\n網站 API 文件 採用 [CC0](http://creativecommons.tw/cc0 \"CC0\")  授權\n\n# § 請自行定義計畫的工作里程碑與最後的驗收標準 （若沒有達成這些標準的話，我們會不給你錢喔！)\n* 前三個月\n   * 系統規劃\n   * 演算法與實作\n      * 語詞行為速描：多語單位、共現環境、時間文類分布\n* 六個月 (驗收標準)\n   * 網站平台上線\n\n# § 未來可能進一步的發展？\n提供商業活動使用\n\n# § 本計畫目前是否已有、或正在申請其他的資金來源？若有，請說明申請本獎助的內容與原計畫的差異。\n無\n\n# § 若有專案介紹的投影片，請提供：\n無","link":"http://lopen.linguistics.ntu.edu.tw/copens/","leader":{"_id":"588f15ab82223f001e0228f2","username":"seantyh","name":"Yu-Hsiang Tseng","picture":"https://avatars.githubusercontent.com/u/4344876?v=3","provider":"github","bio":"臺大心理所博士生，從心理語言學進入語言學研究，並因興趣走入計算語言。同時亦參加臺大語言所LOPE研究室，希望能為語言處理提供更多生命力。\n\n在研究求學期間，曾廣泛應用電腦語言協助處理研究問題，包括曾用C++寫過NLP pipeline（斷詞、詞類標記、剖析器），R與Python的文字或統計資料處理，用C#寫使用者介面、用Java與其他工具做橋接等，還有因為興趣碰了一些些F#和Haskell。在過程中，我相信人類和電腦應當一起共生共榮，而彼此能整合的關鍵，在於一個好的語言橋樑。\n\n語言應該是個多維度的東西，它/他/她絕對是豐富的：人類的語言，電腦的語言；拿來溝通的語言，用來展現結構的語言，拿來操作計算的語言；文學的語言，語言學的語言，心理學的語言。在語言之中，希望能找到我的家。","created_at":"2017-01-30T10:30:03.343Z","admin_in":[]},"domain":"2017spring","cover":"/uploads/7fb3a2069393fcb45d5b00297612506f.png","created_at":"2017-01-31T12:37:10.204Z","updated_at":"2017-02-08T04:38:30.180Z","tags":["自然語言處理","文本分析","語詞行為素描","新詞存活力","NLP"],"finalist":true,"awarded":false,"followers":[{"_id":"5890a54d725c74001e881894","username":"李智堯","name":"李智堯","picture":"https://fb-s-d-a.akamaihd.net/h-ak-xta1/v/t1.0-1/p50x50/14632990_1174671599318646_5450167943333490331_n.jpg?oh=55daef175b3d47c44ccd19e018ad1bed&oe=5917A6E0&__gda__=1494515984_0eaeaae0519f18b0d7c951d3f7f399cd","provider":"facebook","created_at":"2017-01-31T14:55:09.584Z","admin_in":[]},{"_id":"58915ae3725c74001e8818e7","username":"loperntu","name":"iakuhs","picture":"https://avatars.githubusercontent.com/u/3098952?v=3","provider":"github","created_at":"2017-02-01T03:49:55.741Z","admin_in":[]},{"_id":"587c717c2aee66001e902872","username":"Silva Shih","name":"Silva Shih","picture":"https://lh5.googleusercontent.com/-bC-dZ_JqdSY/AAAAAAAAAAI/AAAAAAAAIIg/3-LJym3RcVM/photo.jpg?sz=50","provider":"google","bio":"","created_at":"2017-01-16T07:08:44.111Z","admin_in":[]},{"_id":"5896bd8617c6f6001e440fa5","username":"Tao-Yi Chang","name":"Tao-Yi Chang","picture":"https://fb-s-d-a.akamaihd.net/h-ak-xlp1/v/t1.0-1/p50x50/16265526_10154155682201120_4160575719289335083_n.jpg?oh=e1e0aa5e4bc884d678d3cc448e24999a&oe=590968D9&__gda__=1493804509_fa6aed0e290341a6e117c7d5230990ef","provider":"facebook","created_at":"2017-02-05T05:52:06.425Z","admin_in":[]},{"_id":"58cbf6a3e8d115001e47eabc","username":"FumiMiyabe","name":"FumiMiyabe","picture":"https://avatars0.githubusercontent.com/u/5206001?v=3","provider":"github","created_at":"2017-03-17T14:45:55.397Z","admin_in":[]},{"_id":"5af10e72a5dd1e001b40d5aa","username":"linekin","name":"Sean Lin","picture":"https://avatars0.githubusercontent.com/u/237479?v=4","provider":"github","created_at":"2018-05-08T02:41:54.036Z","admin_in":[]},{"_id":"61150e18c9b274001bdf66d6","username":"Charles Peng","name":"Charles Peng","picture":"https://lh3.googleusercontent.com/a/AATXAJxRXMQgO1jny7b9JKVWEsiWUwlr2B0wtOQSVMcI=s50-mo","provider":"google","created_at":"2021-08-12T12:03:36.696Z","admin_in":[]}],"contributors":[{"_id":"588f15ab82223f001e0228f2","username":"seantyh","name":"Yu-Hsiang Tseng","picture":"https://avatars.githubusercontent.com/u/4344876?v=3","provider":"github","bio":"臺大心理所博士生，從心理語言學進入語言學研究，並因興趣走入計算語言。同時亦參加臺大語言所LOPE研究室，希望能為語言處理提供更多生命力。\n\n在研究求學期間，曾廣泛應用電腦語言協助處理研究問題，包括曾用C++寫過NLP pipeline（斷詞、詞類標記、剖析器），R與Python的文字或統計資料處理，用C#寫使用者介面、用Java與其他工具做橋接等，還有因為興趣碰了一些些F#和Haskell。在過程中，我相信人類和電腦應當一起共生共榮，而彼此能整合的關鍵，在於一個好的語言橋樑。\n\n語言應該是個多維度的東西，它/他/她絕對是豐富的：人類的語言，電腦的語言；拿來溝通的語言，用來展現結構的語言，拿來操作計算的語言；文學的語言，語言學的語言，心理學的語言。在語言之中，希望能找到我的家。","created_at":"2017-01-30T10:30:03.343Z","admin_in":[]}],"status":"brainstorming","revisions":[{"description":"# § 請以 80 ~ 120 字簡短地說明這個專案\n每日產生的開放政府資料含有大量的文本訊息，隨著影音資料的逐字稿自動化技術快速進展，文本分析 (text analytics) 是要了解觀點，呈現事實與多元價值者必備的瑞士刀。目前開源的軟體工具並沒有跟上自然語言處理的新發展，\n這個專案想要來當這個沒有人。\n\n# § 你過去參與過什麼開源開發計畫（open source project）？\n開放中文語料庫計劃 (Corpora Open and Search, COPENS)\n開放中文詞彙語意網路 (Chinese Wordnet, CWN)\n\n# § 這個計畫要解決什麼問題？\n解決 text mining 技術的老舊。每個人都使用一樣的套件 (tm, jieba) 與功能，讓文本分析都長一樣。除了斷詞，關鍵詞擷取，關聯詞/語意距離，詞頻為主的文字雲 之外，我們要提供比較深層的「語詞的行為素描」，包括：\n* (多語單位）lexical bundles(congram)/MWE\n*  (共現環境) concordance, collocation, colligation, lexical network（LSA, embeddings, social network of the lexicon）\n* (時間文類分佈）time-series analysis 語詞的時序分析，新詞存活力指標 stabilization measure。\n\n# § 你為什麼要做這個計劃 （ 個人動機 ）？\n文本語意技術應該要來，也有潛力協助國會監督與公民社會發展。\n\n# § 你預計用什麼方式解決此問題？\n我們想要提供一個開放平台，使用者不需程式背景也可以自由上傳與分享文本語料，分析深度文本語意；\n也可以提供開放函式(cf. OpenCPU, https://www.opencpu.org/)\n\n# § 這個計畫的目標對象是誰？\n任何需要好玩一點的文本分析工具的公民黑客\n\n# § 這個計畫預計跟什麼團體合作？\n台灣大學語言學研究所 LOPE lab, 零時政府與文本挖掘有興趣的團體\n\n# § 過去有作過相關主題的計畫嗎？\nCOPENS http://lopen.linguistics.ntu.edu.tw/copens/\nPTT corpus http://lopen.linguistics.ntu.edu.tw/pttcorp/\nChinese WordSketch Engine http://wordsketch.ling.sinica.edu.tw/\n\n# § 預計六個月內將花多少小時作這件事？需要多少經費？（30 萬到 50 萬）\n* 960 小時（預估每週 10 小時/人 ）\n* 47 萬元（預估開發經費）：\n   - 爬資料、設計、前後端、演算法 (40 萬)\n   - 雲端伺服器租借維護：(5 萬)\n   - 推廣行銷、使用者回饋：(2 萬)\n\n# § 打算如何讓社群參與以及回饋意見？\n* FB 粉絲帳號\n* 將進度的成果在社群的社團(R MLDM Monday, Taipei.py)分享，徵求意見。\n\n# § 請說明專案結束時，會產出的開源軟體套件或開放授權文件（請條列個別元件的輸入輸出或其功能）？\n程式碼採用 [MIT](https://hackmd.io/AwQwrAxsBM0KYFoDscCMAzBAWAHCRARqgJzEJjpwQDMAJkmFsXNUA=== MIT)  授權\n網站 API 文件 採用 [CC0](http://creativecommons.tw/cc0 CC0)  授權\n\n# § 請自行定義計畫的工作里程碑與最後的驗收標準 （若沒有達成這些標準的話，我們會不給你錢喔！)\n* 前三個月\n   * 系統規劃\n   * 演算法與實作\n* 六個月 (驗收標準)\n   * 網站平台上線\n\n# § 未來可能進一步的發展？\n提供商業活動使用\n\n# § 本計畫目前是否已有、或正在申請其他的資金來源？若有，請說明申請本獎助的內容與原計畫的差異。\n無\n\n# § 若有專案介紹的投影片，請提供：\n無","timestamp":"2017-01-31T12:40:40.897Z","_id":"589085c846da1c001e3601dd"},{"description":"# § 請以 80 ~ 120 字簡短地說明這個專案\n每日產生的開放政府資料含有大量的文本訊息，隨著影音資料的逐字稿自動化技術快速進展，文本分析 (text analytics) 是要了解觀點，呈現事實與多元價值者必備的瑞士刀。目前開源的軟體工具並沒有跟上自然語言處理的新發展，\n這個專案想要來當這個沒有人。\n\n# § 你過去參與過什麼開源開發計畫（open source project）？\n* 開放中文語料庫計劃 (Corpora Open and Search, COPENS)\n* 開放中文詞彙語意網路 (Chinese Wordnet, CWN)\n\n# § 這個計畫要解決什麼問題？\n解決 text mining 技術的老舊。每個人都使用一樣的套件 (tm, jieba) 與功能，讓文本分析都長一樣。除了斷詞，關鍵詞擷取，關聯詞/語意距離，詞頻為主的文字雲 之外，我們要提供比較深層的「語詞的行為素描」，包括：\n* (多語單位）lexical bundles(congram)/MWE\n*  (共現環境) concordance, collocation, colligation, lexical network（LSA, embeddings, social network of the lexicon）\n* (時間文類分佈）time-series analysis 語詞的時序分析，新詞存活力指標 stabilization measure。\n\n# § 你為什麼要做這個計劃 （ 個人動機 ）？\n文本語意技術應該要來，也有潛力協助國會監督與公民社會發展。\n\n# § 你預計用什麼方式解決此問題？\n我們想要提供一個開放平台，使用者不需程式背景也可以自由上傳與分享文本語料，分析深度文本語意；\n也可以提供開放函式(cf. OpenCPU, https://www.opencpu.org/)\n\n# § 這個計畫的目標對象是誰？\n任何需要好玩一點的文本分析工具的公民黑客\n\n# § 這個計畫預計跟什麼團體合作？\n台灣大學語言學研究所 LOPE lab, 零時政府與文本挖掘有興趣的團體\n\n# § 過去有作過相關主題的計畫嗎？\n* COPENS [http://lopen.linguistics.ntu.edu.tw/copens/] (http://lopen.linguistics.ntu.edu.tw/copens/)\n* PTT corpus [http://lopen.linguistics.ntu.edu.tw/pttcorp/] (http://lopen.linguistics.ntu.edu.tw/pttcorp/)\n* Chinese WordSketch Engine [http://wordsketch.ling.sinica.edu.tw/] (http://wordsketch.ling.sinica.edu.tw/)\n\n# § 預計六個月內將花多少小時作這件事？需要多少經費？（30 萬到 50 萬）\n* 960 小時（預估每週 10 小時/人 ）\n* 47 萬元（預估開發經費）：\n   - 爬資料、設計、前後端、演算法 (40 萬)\n   - 雲端伺服器租借維護：(5 萬)\n   - 推廣行銷、使用者回饋：(2 萬)\n\n# § 打算如何讓社群參與以及回饋意見？\n* FB 粉絲帳號\n* 將進度的成果在社群的社團(R MLDM Monday, Taipei.py)分享，徵求意見。\n\n# § 請說明專案結束時，會產出的開源軟體套件或開放授權文件（請條列個別元件的輸入輸出或其功能）？\n程式碼採用 [MIT](https://hackmd.io/AwQwrAxsBM0KYFoDscCMAzBAWAHCRARqgJzEJjpwQDMAJkmFsXNUA=== \"MIT\")  授權\n網站 API 文件 採用 [CC0](http://creativecommons.tw/cc0 \"CC0\")  授權\n\n# § 請自行定義計畫的工作里程碑與最後的驗收標準 （若沒有達成這些標準的話，我們會不給你錢喔！)\n* 前三個月\n   * 系統規劃\n   * 演算法與實作\n* 六個月 (驗收標準)\n   * 網站平台上線\n\n# § 未來可能進一步的發展？\n提供商業活動使用\n\n# § 本計畫目前是否已有、或正在申請其他的資金來源？若有，請說明申請本獎助的內容與原計畫的差異。\n無\n\n# § 若有專案介紹的投影片，請提供：\n無","timestamp":"2017-01-31T14:23:58.644Z","_id":"58909dfe725c74001e881881"},{"description":"# § 請以 80 ~ 120 字簡短地說明這個專案\n每日產生的開放政府資料含有大量的文本訊息，隨著影音資料的逐字稿自動化技術快速進展，文本分析 (text analytics) 是要了解觀點，呈現事實與多元價值者必備的瑞士刀。目前開源的軟體工具並沒有跟上自然語言處理的新發展，\n這個專案想要來當這個沒有人。\n\n# § 你過去參與過什麼開源開發計畫（open source project）？\n* 開放中文語料庫計劃 (Corpora Open and Search, COPENS)\n* 開放中文詞彙語意網路 (Chinese Wordnet, CWN)\n\n# § 這個計畫要解決什麼問題？\n解決 text mining 技術的老舊。每個人都使用一樣的套件 (tm, jieba) 與功能，讓文本分析都長一樣。除了斷詞，關鍵詞擷取，關聯詞/語意距離，詞頻為主的文字雲 之外，我們要提供比較深層的「語詞的行為素描」，包括：\n* (多語單位）lexical bundles(congram)/MWE\n*  (共現環境) concordance, collocation, colligation, lexical network（LSA, embeddings, social network of the lexicon）\n* (時間文類分佈）time-series analysis 語詞的時序分析，新詞存活力指標 stabilization measure。\n\n# § 你為什麼要做這個計劃 （ 個人動機 ）？\n文本語意技術應該要來，也有潛力協助國會監督與公民社會發展。\n\n# § 你預計用什麼方式解決此問題？\n我們想要提供一個開放平台，使用者不需程式背景也可以自由上傳與分享文本語料，分析深度文本語意；\n也可以提供開放函式(cf. OpenCPU, https://www.opencpu.org/)\n\n# § 這個計畫的目標對象是誰？\n任何需要好玩一點的文本分析工具的公民黑客\n\n# § 這個計畫預計跟什麼團體合作？\n台灣大學語言學研究所 LOPE lab, 零時政府與文本挖掘有興趣的團體\n\n# § 過去有作過相關主題的計畫嗎？\n* COPENS [http://lopen.linguistics.ntu.edu.tw/copens/] (http://lopen.linguistics.ntu.edu.tw/copens/)\n* PTT corpus [http://lopen.linguistics.ntu.edu.tw/pttcorp/] (http://lopen.linguistics.ntu.edu.tw/pttcorp/)\n* Chinese WordSketch Engine [http://wordsketch.ling.sinica.edu.tw/] (http://wordsketch.ling.sinica.edu.tw/)\n\n# § 預計六個月內將花多少小時作這件事？需要多少經費？（30 萬到 50 萬）\n* 960 小時（預估每週 10 小時/人 ）\n* 47 萬元（預估開發經費）：\n   - 爬資料、設計、前後端、演算法 (40 萬)\n   - 雲端伺服器租借維護：(5 萬)\n   - 推廣行銷、使用者回饋：(2 萬)\n\n# § 打算如何讓社群參與以及回饋意見？\n* FB 粉絲帳號\n* 將進度的成果在社群的社團(R MLDM Monday, Taipei.py)分享，徵求意見。\n\n# § 請說明專案結束時，會產出的開源軟體套件或開放授權文件（請條列個別元件的輸入輸出或其功能）？\n程式碼採用 [MIT](https://hackmd.io/AwQwrAxsBM0KYFoDscCMAzBAWAHCRARqgJzEJjpwQDMAJkmFsXNUA=== \"MIT\")  授權\n網站 API 文件 採用 [CC0](http://creativecommons.tw/cc0 \"CC0\")  授權\n\n# § 請自行定義計畫的工作里程碑與最後的驗收標準 （若沒有達成這些標準的話，我們會不給你錢喔！)\n* 前三個月\n   * 系統規劃\n   * 演算法與實作\n* 六個月 (驗收標準)\n   * 網站平台上線\n\n# § 未來可能進一步的發展？\n提供商業活動使用\n\n# § 本計畫目前是否已有、或正在申請其他的資金來源？若有，請說明申請本獎助的內容與原計畫的差異。\n無\n\n# § 若有專案介紹的投影片，請提供：\n無","timestamp":"2017-02-03T05:15:43.519Z","_id":"589411ff725c74001e881993"},{"description":"# § 請以 80 ~ 120 字簡短地說明這個專案\n每日產生的開放政府資料含有大量的文本訊息，隨著影音資料的逐字稿自動化技術快速進展，文本分析 (text analytics) 是要了解觀點，呈現事實與多元價值者必備的瑞士刀。目前開源的軟體工具並沒有跟上自然語言處理的新發展，\n這個專案想要來當這個沒有人。\n\n# § 你過去參與過什麼開源開發計畫（open source project）？\n* 開放中文語料庫計劃 (Corpora Open and Search, COPENS)\n* 開放中文詞彙語意網路 (Chinese Wordnet, CWN)\n\n# § 這個計畫要解決什麼問題？\n解決 text mining 技術的老舊。每個人都使用一樣的套件 (tm, jieba) 與功能，讓文本分析都長一樣。除了斷詞，關鍵詞擷取，關聯詞/語意距離，詞頻為主的文字雲 之外，我們要提供比較深層的「語詞的行為素描」，包括：\n* (多語單位）lexical bundles(congram)/MWE\n*  (共現環境) concordance, collocation, colligation, lexical network（LSA, embeddings, social network of the lexicon）\n* (時間文類分佈）time-series analysis 語詞的時序分析，新詞存活力指標 stabilization measure。\n\n本專案成果亦可應用至不同國家或地區的中文。我們的團隊對於處理「世界華語」(World Chineses) 有基本的前處理經驗。例如，前處理中最重要的一個步驟是「斷詞」，我們曾經比較過不同斷詞器的結果（包括北京清華大學的分詞器THULAC、香港的切詞器LIVAC，和臺大語言所的深度斷詞DeepSeg）。在實作上，我們將針對不同語料地區來源提供選擇界面，經過不同前處理之後，後續的處理工具即可一體適用。\n\n# § 你為什麼要做這個計劃 （ 個人動機 ）？\n文本語意技術應該要來，也有潛力協助國會監督與公民社會發展。\n\n# § 你預計用什麼方式解決此問題？\n我們想要提供一個開放平台，使用者不需程式背景也可以自由上傳與分享文本語料，分析深度文本語意；\n也可以提供開放函式(cf. OpenCPU, https://www.opencpu.org/)\n\n# § 這個計畫的目標對象是誰？\n任何需要好玩一點的文本分析工具的公民黑客\n\n# § 這個計畫預計跟什麼團體合作？\n台灣大學語言學研究所 LOPE lab, 零時政府與文本挖掘有興趣的團體\n\n# § 過去有作過相關主題的計畫嗎？\n* COPENS [http://lopen.linguistics.ntu.edu.tw/copens/] (http://lopen.linguistics.ntu.edu.tw/copens/)\n* PTT corpus [http://lopen.linguistics.ntu.edu.tw/pttcorp/] (http://lopen.linguistics.ntu.edu.tw/pttcorp/)\n* Chinese WordSketch Engine [http://wordsketch.ling.sinica.edu.tw/] (http://wordsketch.ling.sinica.edu.tw/)\n\n# § 預計六個月內將花多少小時作這件事？需要多少經費？（30 萬到 50 萬）\n* 960 小時（預估每週 10 小時/人 ）\n* 47 萬元（預估開發經費）：\n   - 爬資料、設計、前後端、演算法 (40 萬)\n   - 雲端伺服器租借維護：(5 萬)\n   - 推廣行銷、使用者回饋：(2 萬)\n\n# § 打算如何讓社群參與以及回饋意見？\n* FB 粉絲帳號\n* 將進度的成果在社群的社團(R MLDM Monday, Taipei.py)分享，徵求意見。\n\n# § 請說明專案結束時，會產出的開源軟體套件或開放授權文件（請條列個別元件的輸入輸出或其功能）？\n程式碼採用 [MIT](https://hackmd.io/AwQwrAxsBM0KYFoDscCMAzBAWAHCRARqgJzEJjpwQDMAJkmFsXNUA=== \"MIT\")  授權\n網站 API 文件 採用 [CC0](http://creativecommons.tw/cc0 \"CC0\")  授權\n\n# § 請自行定義計畫的工作里程碑與最後的驗收標準 （若沒有達成這些標準的話，我們會不給你錢喔！)\n* 前三個月\n   * 系統規劃\n   * 演算法與實作\n* 六個月 (驗收標準)\n   * 網站平台上線\n\n# § 未來可能進一步的發展？\n提供商業活動使用\n\n# § 本計畫目前是否已有、或正在申請其他的資金來源？若有，請說明申請本獎助的內容與原計畫的差異。\n無\n\n# § 若有專案介紹的投影片，請提供：\n無","timestamp":"2017-02-08T04:38:30.177Z","_id":"589aa0c6b40f2e001e6317c9"}]}