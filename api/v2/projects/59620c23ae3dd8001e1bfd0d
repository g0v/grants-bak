{"_id":"59620c23ae3dd8001e1bfd0d","title":"親民上河圖","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/Stufinite/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式\n\n讓大佳能自由選擇想接收的資訊\n\n以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元\n\n這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實\n\n更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看\n\n與過去傳統媒體相比是截然不同的\n\n因此，如何分析並利用於社群媒體上群眾之情緒與想法\n\n來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題\n\n\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統\n\n我們稱之為親民上河圖\n\n製作此系統的動機在於改變現有以問卷或電話民調之作法\n\n使民調更貼近民眾真實的意見\n\n原因如下：傳統民調每次的調查成本皆為10萬元起跳\n\n欲設計出具信效度的問卷須請專家檢視並進行前測\n\n從問卷發放到分析結果出爐通常會耗費幾個月的時間\n\n由上述可知，傳統民調實施一次耗費的成本過高\n\n不適用在主題多變、時間緊迫的政策、公共議題上面\n\n問卷的結果也侷限於問卷問題，事後無法再追加其他問題\n\n所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法\n\n使調查結果更貼近現況","solution":"研究方法與步驟：  \n\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。  \n\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n \n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。 \n\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n5. ADABOOST能讓弱分類器再次進化：\n\n### 目前結果：  \n\n|分類器| AUC|\n|----------|--------|\n|原始分類器 | 0.54|\n|BEST FEATURES | 0.74902723735408561|\n|WORD2VEC擴充 | 0.75291828793774318|\n|向量 | 0.78515625|\n|adaboost |  0.822250556|","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳  \n欲設計出具信效度的問卷須請專家檢視並進行前測  \n從問卷發放到分析結果出爐通常會耗費幾個月的時間  \n由上述可知，傳統民調實施一次耗費的成本過高   \n不適用在主題多變、時間緊迫的政策、公共議題上面  \n問卷的結果也侷限於問卷問題，事後無法再追加其他問題  \n所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法  \n使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：[https://github.com/david30907d](https://github.com/david30907d)\n* 實驗室的專案8成我有貢獻：[https://github.com/udicatnchu](https://github.com/udicatnchu)\n* 中興大學學生會蠻多專案我有參與：[https://github.com/NCHUSG](https://github.com/NCHUSG)","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去並且負擔伺服器租金\n","otherfund":"#### 目前專案使用的情緒分析的演算法有通過科技部大專生研究計畫  \n####  僅有演算法而非整個專案獲得補助\n#### 有一位團隊成員與其指導教授進行此情緒分析演算法的研究\n獲得新臺幣四萬八千元的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:  \n\n1. 需有學術價值、演算法上的貢獻，所以一定要有學理上的貢獻。科技部不是補助專案的社會公益。因為這個方向所以科技部補助經費必須用在演算法的開發上，無法把重心放在公民議題上\n2. 不需要為open source（但是此演算法已經是python開源套件）\n3. 不一定要具社會公益\n4. 經費運用受限於學校","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","link":"http://140.120.13.243:8001/","leader":{"_id":"5961a75fae3dd8001e1bfd0b","username":"david30907d","name":"張泰瑋(Chang Tai Wei)","picture":"https://avatars3.githubusercontent.com/u/9366404?v=4","provider":"github","bio":"https://david30907d.github.io/home/","created_at":"2017-07-09T03:47:43.161Z","admin_in":[]},"cover":"/uploads/ae717c6962c7747a498e889a786c0762.png","domain":"2017autumn","created_at":"2017-07-09T10:57:39.215Z","updated_at":"2017-07-29T14:49:34.730Z","tags":["政策","民調","情緒判斷","機器學習"],"finalist":false,"awarded":false,"followers":[{"_id":"5961a75fae3dd8001e1bfd0b","username":"david30907d","name":"張泰瑋(Chang Tai Wei)","picture":"https://avatars3.githubusercontent.com/u/9366404?v=4","provider":"github","bio":"https://david30907d.github.io/home/","created_at":"2017-07-09T03:47:43.161Z","admin_in":[]},{"_id":"5963836eae3dd8001e1bfd3f","username":"官方信箱 Stufinite","name":"官方信箱 Stufinite","picture":"https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=50","provider":"google","created_at":"2017-07-10T13:38:54.407Z","admin_in":[]},{"_id":"5968d5c9d60a0d001ed1f7d0","username":"陳建訓","name":"陳建訓","picture":"https://fb-s-b-a.akamaihd.net/h-ak-fbx/v/t1.0-1/p50x50/12063613_1211331532225375_2226739967671901423_n.jpg?oh=10b4aaf15431c00ccf1f471301320dc8&oe=59FF49B7&__gda__=1506130415_afddce920faed5a8dc0163941866d1ae","provider":"facebook","created_at":"2017-07-14T14:31:37.597Z","admin_in":[]}],"contributors":[{"_id":"5961a75fae3dd8001e1bfd0b","username":"david30907d","name":"張泰瑋(Chang Tai Wei)","picture":"https://avatars3.githubusercontent.com/u/9366404?v=4","provider":"github","bio":"https://david30907d.github.io/home/","created_at":"2017-07-09T03:47:43.161Z","admin_in":[]}],"status":"brainstorming","revisions":[{"timestamp":"2017-07-09T10:58:38.016Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    1. Logistic Regression – best features：0.74902723735408561\n    2. Logistic Regression - word2vec擴充：0.75291828793774318\n    3. Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"#等等補上\n本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的評價，容易對各縣市的評價結果進行比較，使政策能夠迅速聽到民眾的心聲，加以改進。本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的評價，容易對各縣市的評價結果進行比較，使政策能夠迅速聽到民眾的心聲，加以改進。====","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"等等寫","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"思考中","milestone2":"思考中","future":"思考中","otherfund":"等等再寫","category":"公共政策","slide":"等等補上","_id":"59620c5eae3dd8001e1bfd0e"},{"timestamp":"2017-07-10T09:03:03.334Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    1. Logistic Regression – best features：0.74902723735408561\n    2. Logistic Regression - word2vec擴充：0.75291828793774318\n    3. Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 等等補上\n本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的評價，容易對各縣市的評價結果進行比較，使政策能夠迅速聽到民眾的心聲，加以改進。本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的評價，容易對各縣市的評價結果進行比較，使政策能夠迅速聽到民眾的心聲，加以改進。====","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"等等寫","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"思考中","milestone2":"思考中","future":"思考中","otherfund":"等等再寫","category":"公共政策","slide":"等等補上","_id":"596342c7ae3dd8001e1bfd25"},{"timestamp":"2017-07-10T09:59:09.327Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    1. Logistic Regression – best features：0.74902723735408561\n    2. Logistic Regression - word2vec擴充：0.75291828793774318\n    3. Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 等等補上\n本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的評價，容易對各縣市的評價結果進行比較，使政策能夠迅速聽到民眾的心聲，加以改進。本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的評價，容易對各縣市的評價結果進行比較，使政策能夠迅速聽到民眾的心聲，加以改進。====","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"等等寫","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"思考中","milestone2":"思考中","future":"思考中","otherfund":"等等再寫","category":"社會參與","slide":"等等補上","_id":"59634fedae3dd8001e1bfd31"},{"timestamp":"2017-07-10T10:00:06.799Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    1. Logistic Regression – best features：0.74902723735408561\n    2. Logistic Regression - word2vec擴充：0.75291828793774318\n    3. Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[!圖片](http://imgur.com/a/dOaZW)\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59635026ae3dd8001e1bfd32"},{"timestamp":"2017-07-10T10:01:03.773Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    1. Logistic Regression – best features：0.74902723735408561\n    2. Logistic Regression - word2vec擴充：0.75291828793774318\n    3. Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"![圖片](http://imgur.com/a/dOaZW)\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"5963505fae3dd8001e1bfd33"},{"timestamp":"2017-07-10T10:01:50.194Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    1. Logistic Regression – best features：0.74902723735408561\n    2. Logistic Regression - word2vec擴充：0.75291828793774318\n    3. Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"![圖片](http://imgur.com/a/dOaZW)\n![剛之煉金術師的怠惰](https://images2.alphacoders.com/231/231210.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"5963508eae3dd8001e1bfd34"},{"timestamp":"2017-07-10T10:02:51.310Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    1. Logistic Regression – best features：0.74902723735408561\n    2. Logistic Regression - word2vec擴充：0.75291828793774318\n    3. Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"![圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596350cbae3dd8001e1bfd35"},{"timestamp":"2017-07-10T10:03:20.216Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n  *. Logistic Regression – best features：0.74902723735408561\n  *. Logistic Regression - word2vec擴充：0.75291828793774318\n  *. Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596350e8ae3dd8001e1bfd36"},{"timestamp":"2017-07-10T10:03:49.906Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：  \n    *. Logistic Regression – best features：0.74902723735408561\n    *. Logistic Regression - word2vec擴充：0.75291828793774318\n    *. Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59635105ae3dd8001e1bfd37"},{"timestamp":"2017-07-10T10:06:36.933Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：  \n    *  Logistic Regression – best features：0.74902723735408561\n    *  Logistic Regression - word2vec擴充：0.75291828793774318\n    *  Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596351acae3dd8001e1bfd38"},{"timestamp":"2017-07-10T11:24:39.026Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了word2vec，將(3)的best features的同義詞也合併best features。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    *  Logistic Regression – best features：0.74902723735408561\n    *  Logistic Regression - word2vec擴充：0.75291828793774318\n    *  Logistic Regression - 向量：0.78515625\n5. adaboost能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596363f7ae3dd8001e1bfd3a"},{"timestamp":"2017-07-10T11:30:28.131Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"Web 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    *  LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    *  LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    *  LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59636554ae3dd8001e1bfd3b"},{"timestamp":"2017-07-10T11:31:18.214Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    *  LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    *  LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    *  LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556\n","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59636586ae3dd8001e1bfd3c"},{"timestamp":"2017-07-10T11:31:49.100Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n  *  LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n  *  LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n  *  LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596365a5ae3dd8001e1bfd3d"},{"timestamp":"2017-07-10T11:32:38.666Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n  * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n  * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n  * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596365d6ae3dd8001e1bfd3e"},{"timestamp":"2017-07-10T13:44:55.903Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n爬取所需的PTT文章作為訓練資料\n將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n引進word2vec，將(4)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n將句子刪除停用詞之後，將每個字的向量合成當作句子的向量。\n使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n(1) (2)都能以多蒐集到的資料當作檢驗標準  \n(3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596384d7ae3dd8001e1bfd40"},{"timestamp":"2017-07-10T13:45:15.004Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596384ebae3dd8001e1bfd42"},{"timestamp":"2017-07-10T13:48:51.410Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%\n語料蒐集：10%\n評比自動化民調準確度的民眾參與經費：20%\n演算法開發：50%","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：\n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：\n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"等等再寫","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596385c3ae3dd8001e1bfd43"},{"timestamp":"2017-07-10T13:49:52.211Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：  \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:  \n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59638600ae3dd8001e1bfd44"},{"timestamp":"2017-07-10T13:50:08.258Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於：  \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59638610ae3dd8001e1bfd45"},{"timestamp":"2017-07-10T13:50:49.000Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做\n但是目前市面上的好像都是付費的\n我想做一個大家想查就查\n然後爬蟲會隨時更新的系統\n這樣就可以隨時follow最新的民調和議題   免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59638639ae3dd8001e1bfd47"},{"timestamp":"2017-07-11T01:54:08.939Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger\n    * 判斷情緒的分類器django版app: 直接 `PIP INSTALL SWINGERAPP`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59642fc0ae3dd8001e1bfd56"},{"timestamp":"2017-07-11T01:54:39.106Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, `pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59642fdfae3dd8001e1bfd57"},{"timestamp":"2017-07-11T01:56:20.410Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59643044ae3dd8001e1bfd58"},{"timestamp":"2017-07-11T02:11:56.377Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。  \n\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n \n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。 \n\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n    * LOGISTIC REGRESSION – BEST FEATURES：0.74902723735408561\n    * LOGISTIC REGRESSION - WORD2VEC擴充：0.75291828793774318\n    * LOGISTIC REGRESSION - 向量：0.78515625\n5. ADABOOST能讓弱分類器再次進化：\n    * AUC最高能到0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596433ecae3dd8001e1bfd5c"},{"timestamp":"2017-07-11T02:12:49.346Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。  \n\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n \n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。 \n\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n5. ADABOOST能讓弱分類器再次進化：\n\n分類器| AUC\n原始分類器 | 0.54\nBEST FEATURES | 0.74902723735408561\nWORD2VEC擴充 | 0.75291828793774318\n向量 | 0.78515625\nadaboost |  0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59643421ae3dd8001e1bfd5d"},{"timestamp":"2017-07-11T02:14:28.685Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。  \n\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n \n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。 \n\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n5. ADABOOST能讓弱分類器再次進化：\n\n分類器| AUC\n----------|--------\n原始分類器 | 0.54\nBEST FEATURES | 0.74902723735408561\nWORD2VEC擴充 | 0.75291828793774318\n向量 | 0.78515625\nadaboost |  0.822250556","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"59643484ae3dd8001e1bfd5e"},{"timestamp":"2017-07-11T02:16:31.301Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。  \n\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n \n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。 \n\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n5. ADABOOST能讓弱分類器再次進化：\n\n### 目前結果：  \n\n|分類器| AUC|\n|----------|--------|\n|原始分類器 | 0.54|\n|BEST FEATURES | 0.74902723735408561|\n|WORD2VEC擴充 | 0.75291828793774318|\n|向量 | 0.78515625|\n|adaboost |  0.822250556|","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間[2]。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596434ffae3dd8001e1bfd5f"},{"timestamp":"2017-07-16T03:08:03.022Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式，讓大佳能自由選擇想接收的資訊，以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元。這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實，更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看，與過去傳統媒體相比是截然不同的。因此，如何分析並利用於社群媒體上群眾之情緒與想法，來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題。  \n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統，我們稱之為親民上河圖。製作此系統的動機在於改變現有以問卷或電話民調之作法，使民調更貼近民眾真實的意見，原因如下：傳統民調每次的調查成本皆為10萬元起跳；欲設計出具信效度的問卷須請專家檢視並進行前測，從問卷發放到分析結果出爐通常會耗費幾個月的時間。由上述可知，傳統民調實施一次耗費的成本過高，不適用在主題多變、時間緊迫的政策、公共議題上面。問卷的結果也侷限於問卷問題，事後無法再追加其他問題。所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法，使調查結果更貼近現況。","solution":"研究方法與步驟：  \n\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。  \n\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n \n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。 \n\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n5. ADABOOST能讓弱分類器再次進化：\n\n### 目前結果：  \n\n|分類器| AUC|\n|----------|--------|\n|原始分類器 | 0.54|\n|BEST FEATURES | 0.74902723735408561|\n|WORD2VEC擴充 | 0.75291828793774318|\n|向量 | 0.78515625|\n|adaboost |  0.822250556|","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳  \n欲設計出具信效度的問卷須請專家檢視並進行前測  \n從問卷發放到分析結果出爐通常會耗費幾個月的時間  \n由上述可知，傳統民調實施一次耗費的成本過高   \n不適用在主題多變、時間緊迫的政策、公共議題上面  \n問卷的結果也侷限於問卷問題，事後無法再追加其他問題  \n所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法  \n使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"596ad893d60a0d001ed1f843"},{"timestamp":"2017-07-28T15:59:34.556Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式\n\n讓大佳能自由選擇想接收的資訊\n\n以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元\n\n這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實\n\n更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看\n\n與過去傳統媒體相比是截然不同的\n\n因此，如何分析並利用於社群媒體上群眾之情緒與想法\n\n來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題\n\n\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統\n\n我們稱之為親民上河圖\n\n製作此系統的動機在於改變現有以問卷或電話民調之作法\n\n使民調更貼近民眾真實的意見\n\n原因如下：傳統民調每次的調查成本皆為10萬元起跳\n\n欲設計出具信效度的問卷須請專家檢視並進行前測\n\n從問卷發放到分析結果出爐通常會耗費幾個月的時間\n\n由上述可知，傳統民調實施一次耗費的成本過高\n\n不適用在主題多變、時間緊迫的政策、公共議題上面\n\n問卷的結果也侷限於問卷問題，事後無法再追加其他問題\n\n所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法\n\n使調查結果更貼近現況","solution":"研究方法與步驟：  \n\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。  \n\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n \n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。 \n\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n5. ADABOOST能讓弱分類器再次進化：\n\n### 目前結果：  \n\n|分類器| AUC|\n|----------|--------|\n|原始分類器 | 0.54|\n|BEST FEATURES | 0.74902723735408561|\n|WORD2VEC擴充 | 0.75291828793774318|\n|向量 | 0.78515625|\n|adaboost |  0.822250556|","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳  \n欲設計出具信效度的問卷須請專家檢視並進行前測  \n從問卷發放到分析結果出爐通常會耗費幾個月的時間  \n由上述可知，傳統民調實施一次耗費的成本過高   \n不適用在主題多變、時間緊迫的政策、公共議題上面  \n問卷的結果也侷限於問卷問題，事後無法再追加其他問題  \n所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法  \n使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"目前該演算法通過科技部大專生研究計畫，獲得4萬八的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:   \n\n1. 不在乎是否為open source\n2. 不在乎是否具社會公益\n3. 需有學術價值、演算法上的貢獻\n4. 經費運用受限於學校\n","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"597b5f66c1a530001e74fc6d"},{"timestamp":"2017-07-28T16:00:21.611Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式\n\n讓大佳能自由選擇想接收的資訊\n\n以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元\n\n這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實\n\n更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看\n\n與過去傳統媒體相比是截然不同的\n\n因此，如何分析並利用於社群媒體上群眾之情緒與想法\n\n來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題\n\n\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統\n\n我們稱之為親民上河圖\n\n製作此系統的動機在於改變現有以問卷或電話民調之作法\n\n使民調更貼近民眾真實的意見\n\n原因如下：傳統民調每次的調查成本皆為10萬元起跳\n\n欲設計出具信效度的問卷須請專家檢視並進行前測\n\n從問卷發放到分析結果出爐通常會耗費幾個月的時間\n\n由上述可知，傳統民調實施一次耗費的成本過高\n\n不適用在主題多變、時間緊迫的政策、公共議題上面\n\n問卷的結果也侷限於問卷問題，事後無法再追加其他問題\n\n所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法\n\n使調查結果更貼近現況","solution":"研究方法與步驟：  \n\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。  \n\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n \n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。 \n\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n5. ADABOOST能讓弱分類器再次進化：\n\n### 目前結果：  \n\n|分類器| AUC|\n|----------|--------|\n|原始分類器 | 0.54|\n|BEST FEATURES | 0.74902723735408561|\n|WORD2VEC擴充 | 0.75291828793774318|\n|向量 | 0.78515625|\n|adaboost |  0.822250556|","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳  \n欲設計出具信效度的問卷須請專家檢視並進行前測  \n從問卷發放到分析結果出爐通常會耗費幾個月的時間  \n由上述可知，傳統民調實施一次耗費的成本過高   \n不適用在主題多變、時間緊迫的政策、公共議題上面  \n問卷的結果也侷限於問卷問題，事後無法再追加其他問題  \n所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法  \n使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"#### 目前專案使用的情緒分析的演算法有通過科技部大專生研究計畫  \n####  僅有演算法而非整個專案\n#### 只有一位團隊成員與其指導教授進行此情緒分析演算法的研究\n獲得新臺幣四萬八千元的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:  \n\n1. 需有學術價值、演算法上的貢獻\n2. 不需要為open source（但是此演算法已經是python開源套件）\n3. 不一定要具社會公益\n4. 經費運用受限於學校","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"597b5f95c1a530001e74fc6e"},{"timestamp":"2017-07-29T14:49:34.729Z","money":500000,"desc":"本研究透過蒐集PTT的使用者留言，進行情緒分析，判斷留言者對於特定的議題（如政治人物、政策）的評價為正面或者負面，且藉由IP反查留言者的居住縣市，統計各縣市對於此議題的評價，並以資料視覺化的方式呈現。藉此得到一個低成本、快速且較全面性的民調","motivation":"他剛好是我大學的專題   一開始教授提了幾個方向讓我們選擇\n我的動機是：其實我本身不是非常關心新聞的人\n大學住宿期間我看不到電視，所以常常跟社會時事脫節\n\n以服貿、廢死為例，有些報紙經常會有政治傾向 \n讓我以為大家都支持或反對這個議題\n但是事實是這樣嘛? \n如果有個系統能自主判斷鄉民的意見\n當作民調的話  我會比較相信這個依據而不是媒體說的","existed":"1. 是開源\n    * 主要api：https://github.com/UDICatNCHU/PTT_KCM_API\n    * 前端：https://github.com/UDICatNCHU/SentiMap\n    * 判斷情緒的分類器：https://github.com/UDICatNCHU/Swinger, 支援：`pip install swinger`\n    * 判斷情緒的分類器django版app: 直接 `pip install swingerapp`\n    * 為了訓練出判斷情緒的分類器所使用到的訓練資料+語料（人工標記）：https://github.com/UDICatNCHU/Open-Sentiment-Training-Data\n2. 網址：http://140.120.13.243:8001/\n    * 目前已經建立快取的議題不多，現場查詢有些要等半小時，目前已經建立好的：蔡英文、馬英九、廢死、同婚、年金","problem":"WEB 2.0時代的到來改變了資訊傳播的方式\n\n讓大佳能自由選擇想接收的資訊\n\n以及藉由在網路上發布文章、上傳資料等方式，讓網路上的數位內容變得更多元\n\n這些由使用者自發性發佈的數位內容，不只是單純的陳述既有事實\n\n更飽含著個人的情緒和看法，使得內容更加豐富且更值得觀看\n\n與過去傳統媒體相比是截然不同的\n\n因此，如何分析並利用於社群媒體上群眾之情緒與想法\n\n來進行群眾對特定議題之情緒觀感分析，也是現代重要的課題\n\n\n有鑑於此，此計劃研究的目的為開發一個基於PTT為基礎之社群媒體輿論分析系統\n\n我們稱之為親民上河圖\n\n製作此系統的動機在於改變現有以問卷或電話民調之作法\n\n使民調更貼近民眾真實的意見\n\n原因如下：傳統民調每次的調查成本皆為10萬元起跳\n\n欲設計出具信效度的問卷須請專家檢視並進行前測\n\n從問卷發放到分析結果出爐通常會耗費幾個月的時間\n\n由上述可知，傳統民調實施一次耗費的成本過高\n\n不適用在主題多變、時間緊迫的政策、公共議題上面\n\n問卷的結果也侷限於問卷問題，事後無法再追加其他問題\n\n所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法\n\n使調查結果更貼近現況","solution":"研究方法與步驟：  \n\n1. 爬取所需的PTT文章作為訓練資料,將訓練資料斷詞後，輸入6種分類器做訓練，並用人工標記過的測試資料檢測訓練結果。  \n\n2. 使用停用詞(stopwords)，斷詞後將停用詞刪除再去訓練，測試成效。\n\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。依照此概念計算訓練資料中所有的卡方，並且由小到大排序並且topN個單字當作best features，訓練資料與測試資料的句子，只留下存在於best features的字去做判斷和訓練，以6種分類器去做分類\n\n4. 引進word2vec，將(3)的best features的同義詞也合併best features。使得分類器（使用表現最穩定的Logistic Regression）能判斷的辭彙增加，並測試其效果。\n \n5. 將句子刪除停用詞之後，透過(4)的word2vec轉換出句子的向量。 \n\n6. 使用adaboost，賦予訓練資料權重並用疊代的方式做分類器的訓練。\n","why":"1. 實驗初期，我們將訓練資料斷詞後，輸入6種分類器做訓練，準確度大約只有54%。\n2. 為了改善準確度，我們蒐集1300個停用詞，斷詞後將停用詞刪除再去訓練，準確度提升至56%，仍然不佳。\n3. 引入卡方的概念，若單字的分佈有偏向正面或負面的文集，則其卡方數值會較高；反之若單字式平均分佈，則卡方會低。\n4. 接著我們引進了WORD2VEC，將(3)的BEST FEATURES的同義詞也合併BEST FEATURES。使得分類器能判斷的辭彙增加，其效果有些微的提升。將句子刪除停用詞之後，將每個字的向量合成當作句子的向量，效果如下：\n5. ADABOOST能讓弱分類器再次進化：\n\n### 目前結果：  \n\n|分類器| AUC|\n|----------|--------|\n|原始分類器 | 0.54|\n|BEST FEATURES | 0.74902723735408561|\n|WORD2VEC擴充 | 0.75291828793774318|\n|向量 | 0.78515625|\n|adaboost |  0.822250556|","ta":"# 目標對象：\n1. 政客\n2. 關心政治議題的民眾  \n\n# 需求、情境與使用動機：\n傳統民調每次的調查成本皆為10萬元起跳  \n欲設計出具信效度的問卷須請專家檢視並進行前測  \n從問卷發放到分析結果出爐通常會耗費幾個月的時間  \n由上述可知，傳統民調實施一次耗費的成本過高   \n不適用在主題多變、時間緊迫的政策、公共議題上面  \n問卷的結果也侷限於問卷問題，事後無法再追加其他問題  \n所以利用社群媒體上群眾之情緒與想法，將有別於現有以問卷與電話民調之作法  \n使調查結果更貼近現況。\n","similar":"使用社群媒體當作民調母體有不少人再做  \n但是目前市面上的好像都是付費的  \n我想做一個大家想查就查  \n然後爬蟲會隨時更新的系統  \n這樣就可以隨時follow最新的民調和議題  \n免錢的話應該就算是不可取代了","refdesign":"[圖片](http://i.imgur.com/bM7u8vz.png)\n\n目前做到這樣\n預計新增一個欄位，會隨機挑選幾筆ptt上關於該議題的評論  \n讓民眾查詢議題的時候\n能檢查一下系統判斷準不準","pastprj":"* 我的：https://github.com/david30907d\n* 實驗室的：https://github.com/udicatnchu","cowork":"跟我的指導教授[范耀中](http://web.nchu.edu.tw/~yfan/) 老師討論\n以及我們的實驗室  UDIC 的成員一起研究","usetime":"125小時","spending":"主機：20%  \n語料蒐集：10%  \n評比自動化民調準確度的民眾參與經費：20%  \n演算法開發：50%  ","feedback":"github上的issue聯絡","product":"GNU3.0","milestone1":"本專案目前需要改進的地方在於： \n \n1. 語料不夠豐富，ptt年齡層偏年輕\n2. 測試資料不夠\n3. 期望能提升分類器的準確度\n\n# 工作里程碑與驗收給付標準：  \n1. (1) (2)都能以多蒐集到的資料當作檢驗標準  \n2. (3) 檢驗分類器在使用同一組test data測試時，是否準確度提高","milestone2":"機器學習所判斷的情緒準確度，即使TEST出來準確度極高  \n仍然不能保證用在未來的議題都有相對的準確度  \n最終目標是期望，機器自動運算的民調  \n能讓使用者覺得有信心\n\n# 工作里程碑與驗收給付標準：\n\n目前文字探勘的領域沒有一個很好的BENCHMARK  \n去衡量我們斷詞、給予情緒標籤等等是好是壞  \n所以希望能在期間內找出好的演算法  若行，就能在數學上證明好壞  \n若不幸沒找出來，就只能交由大眾判斷機器準確度  ","future":"期望能找到贊助商或政治人物的贊助\n即使未來我去工作不再投入開發\n也能夠自主的營運下去","otherfund":"#### 目前專案使用的情緒分析的演算法有通過科技部大專生研究計畫  \n####  僅有演算法而非整個專案獲得補助\n#### 有一位團隊成員與其指導教授進行此情緒分析演算法的研究\n獲得新臺幣四萬八千元的補助  \n該計畫性質類似於學校的研究  \n與g0v的差異在於:  \n\n1. 需有學術價值、演算法上的貢獻\n2. 不需要為open source（但是此演算法已經是python開源套件）\n3. 不一定要具社會公益\n4. 經費運用受限於學校","category":"社會參與","slide":"http://prezi.com/alk4cbm5qtc2/?utm_campaign=share&utm_medium=copy&rc=ex0share","_id":"597ca07ec1a530001e74fcb2"}]}